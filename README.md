# FPGA-Based MNIST Digit Recognition Accelerator
## High-Throughput Parallel Neural Network Inference in SystemVerilog

### Project Overview
This project implements a hardware-accelerated Digit Recognition system based on the MNIST dataset. The system utilizes a Logistic Regression model implemented in SystemVerilog, optimized for high-speed inference on FPGA hardware. By leveraging a parallel architecture, the design calculates classification scores for all ten possible digits (0-9) simultaneously, achieving high throughput and low latency.

### Mathematical Background

#### 1. Fixed-Point Arithmetic (Q4.12)
To optimize hardware resource usage and avoid the overhead of floating-point units, this implementation employs a **Q4.12 fixed-point format**.
* **Scaling:** All model weights and input pixel values are scaled by a factor of 4096 ($2^{12}$).
* **Precision:** The MAC (Multiply-Accumulate) unit performs signed 16-bit multiplication and uses an arithmetic right shift of 12 bits ($>>> 12$) to maintain the fixed-point alignment.

#### 2. Inference Logic
The system classifications are based on calculating the weighted sum for each of the 10 output neurons:
$$Score_i = \sum_{j=1}^{784} (Pixel_j \times Weight_{i,j})$$
The final prediction is determined by an **Argmax** function, which identifies the neuron index with the highest accumulated score.

### Hardware Architecture
The design follows a modular streaming architecture composed of the following components:
* **FSM Controller:** A state machine managing four states: `IDLE`, `INIT` (accumulator reset), `CALC` (streaming 784 pixels), and `DONE`.
* **Weight Memory:** Internal memory modules initialized with pre-trained weights from `weights.mem`.
* **Parallel Neuron Layer:** Ten parallel `neuron_top` instances that process the input stream concurrently.
* **MAC Unit:** The core computational engine that performs multiplication and accumulation for each pixel-weight pair.
* **Argmax Logic:** Combinational comparator logic that determines the winning digit class.

### Neuron Block Diagram
<img width="320" height="220" alt="Screenshot 2026-01-17 at 14 36 30" src="https://github.com/user-attachments/assets/9e5f9564-feca-46e1-affa-4b057856ea71" />

### Layer Block Diagram
<img width="500" height="400" alt="Screenshot 2026-01-17 at 14 37 04" src="https://github.com/user-attachments/assets/4e04ae81-545b-4b62-8c7f-04427fba3535" />


### Results
The implementation has been verified for both accuracy and computational correctness:
* **Verification:** Achieved a **100% match** between hardware calculation results and the Python-based Golden Reference.
* **Model Performance:** The system maintains a classification accuracy of **91%** on the MNIST test set.
* **Confidence Analysis:** Visual plots generated by the verification suite confirm that the hardware correctly identifies digits even when visual similarities exist (e.g., between digits 3 and 5).

<img width="1500" height="500" alt="Figure_1" src="https://github.com/user-attachments/assets/1887a021-7150-400a-8a64-5426664155fb" />

### File Structure
```text
MNIST-Accelerator/
├── rtl/                    # SystemVerilog Hardware Description
│   ├── layer_top.sv          # Top-level: Parallel neurons & Argmax logic
│   ├── neuron_top.sv         # Neuron module integration
│   ├── controller.sv         # FSM and address generation
│   ├── mac_unit.sv           # Signed Q4.12 MAC unit
│   └── weight_memory.sv      # BRAM-based weight storage
├── python/                 # Software Toolchain
│   ├── gen_image.py          # Training and .mem file generation
│   └── verify_results.py     # Hardware vs. Software verification
├── data/                   # Simulation Data (Weights, Images, Scores)
├── images/                 # Result Visualization Plots
└── tb/                     # Verification Testbenches
